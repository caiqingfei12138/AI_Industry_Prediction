{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "这个特征工程主要是用KNN对数据进行填充\n",
    "'''\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_excel('H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\seconddata\\\\raw_data\\\\训练_20180117.xlsx')\n",
    "test_A = pd.read_excel('H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\seconddata\\\\raw_data\\\\测试A_20180117.xlsx')\n",
    "test_B = pd.read_excel('H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\seconddata\\\\raw_data\\\\测试B_20180117.xlsx')\n",
    "train_data = pd.concat([train,test_A,test_B]) # ignore_index=False\n",
    "data = train_data.drop('ID',axis=1)\n",
    "target = data['Value']\n",
    "target = target[0:800]\n",
    "data = data.drop('Value',axis=1)\n",
    "missing_count = data.apply(lambda x: sum(x.isnull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1，删除缺失较多的特征\n",
    "more_missing = missing_count[missing_count>=1511]\n",
    "more_missing_index = list(more_missing.index)\n",
    "data = data.drop(more_missing_index,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 取出tool_ID\n",
    "tool_cols = ['TOOL' , 'Tool', 'TOOL_ID','Tool (#1)','TOOL (#1)','TOOL (#2)',\n",
    "                 'Tool (#2)','Tool (#3)','Tool (#4)','OPERATION_ID','Tool (#5)','TOOL (#3)']\n",
    "gongxue_data = data[tool_cols]\n",
    "\n",
    "data=data.drop(tool_cols,axis=1)\n",
    "\n",
    "data.to_excel(  'H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\runtime_schame\\\\feature2\\\\data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载KNN填充后的数据\n",
    "data = pd.read_excel(  'H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\runtime_schame\\\\feature2\\\\imputed_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 方差分析\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    " \n",
    "#方差选择法，返回值为特征选择后的数据\n",
    "#参数threshold为方差的阈值\n",
    "VarianceThreshold_data = pd.DataFrame(VarianceThreshold(threshold=0.005).fit_transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#区间缩放，返回值为缩放到[0, 1]区间的数据\n",
    "MinMaxScaler_data = pd.DataFrame(MinMaxScaler().fit_transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-Hot Encode\n",
    "one_hot = pd.get_dummies(gongxue_data, columns=tool_cols)\n",
    "# onhot concat with VarianceThreshold_da\n",
    "one_hot= one_hot.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#数据拼接\n",
    "one_var_data=pd.concat([one_hot,MinMaxScaler_data],axis=1,ignore_index=False)\n",
    "\n",
    "train = one_var_data.ix[0:799,:]\n",
    "testA = one_var_data.ix[800:1099,:]\n",
    "testB = one_var_data.ix[1100:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 5910) (800,)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape,target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM--MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0\n",
      "0  0.021132\n",
      "1  0.017438\n",
      "2  0.018243\n",
      "3  0.019058\n",
      "4  0.026755\n",
      "5  0.020205\n",
      "6  0.016217\n",
      "7  0.019704\n",
      "8  0.017440\n",
      "9  0.017433\n",
      "-----------------------------------------\n",
      "0.0193624612866\n"
     ]
    }
   ],
   "source": [
    "# build moudel\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.linear_model.base import LinearRegression\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPRegressor\n",
    "from sklearn.svm.classes import SVR\n",
    "from sklearn.tree.tree import ExtraTreeRegressor, DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor\n",
    "mse = []\n",
    "sum_mse = 0.0\n",
    "B = pd.DataFrame(np.zeros((300,10)))\n",
    "for index in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target,test_size=0.25) \n",
    "    model=SVR(kernel='rbf', \n",
    "                degree=5,\n",
    "#                 gamma= 0.001,\n",
    "                gamma = 'auto' ,\n",
    "                coef0=0.1, \n",
    "                tol=0.001, \n",
    "                C=2,\n",
    "                epsilon= 0.05, \n",
    "                shrinking=True, \n",
    "                cache_size=500, \n",
    "                verbose=False, \n",
    "                max_iter=-1)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    sum_mse += mean_squared_error(y_test,y_pred)\n",
    "    mse.append(mean_squared_error(y_test,y_pred))\n",
    "    predict = pd.DataFrame(model.predict(testA))\n",
    "    B[index] = predict\n",
    "#         print(\"index: \",index,mean_squared_error(y_test,y_pred))\n",
    "print(pd.DataFrame(mse))\n",
    "print('-----------------------------------------')\n",
    "print(sum_mse/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "B.to_csv( 'H:\\\\java\\\\python\\\\src\\\\machinelearning\\\\runtime_schame\\\\feature2\\\\svr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB--MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "# build moudel\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import ensemble, linear_model\n",
    "from sklearn.linear_model.base import LinearRegression\n",
    "from sklearn.neural_network.multilayer_perceptron import MLPRegressor\n",
    "from sklearn.svm.classes import SVR\n",
    "from sklearn.tree.tree import ExtraTreeRegressor, DecisionTreeRegressor\n",
    "from sklearn.ensemble.bagging import BaggingRegressor\n",
    "mse = []\n",
    "B = pd.DataFrame(np.zeros((300,10)))\n",
    "sum_mse = 0.0\n",
    "\n",
    "for index in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target,test_size=0.1) \n",
    "    model = xgb.XGBRegressor(model = xgb.XGBRegressor(max_depth=6, # 8    此处MSE为0.013\n",
    "                                     min_child_weigh=5,\n",
    "                                     eta=0.1,\n",
    "                                     gamma=0.06,\n",
    "                                     subsample=0.8,\n",
    "                                     learning_rate=0.01, \n",
    "                                     n_estimators=1000, \n",
    "                                     silent=0, \n",
    "                                     n_jobs=-1,\n",
    "                                     objective='reg:linear')\n",
    "                               )\n",
    "                            \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse.append(mean_squared_error(y_test,y_pred))\n",
    "    sum_mse += mean_squared_error(y_test,y_pred)\n",
    "    predict = pd.DataFrame(model.predict(testA))\n",
    "    B[index] = predict\n",
    "print(pd.DataFrame(mse))\n",
    "print('------------------------------------------------------------')\n",
    "print(sum_mse/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
